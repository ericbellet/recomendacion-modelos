# Multiplicacion Matriz por Vector usando mapreduce
# Tipo 1: el caso en que el vector v cabe dentro de la memoria RAM
MultMV_1.mr <- function( M, V) {
d <- values(from.dfs(V))
f <- function(x){return(x[3]*d[x[2],2])}
map <- function(.,m) {
i <- m[1]
m <- as.matrix(m)
valor <- apply(m,1,f)
valor <- as.data.frame(as.numeric(as.character(valor)))
return( keyval(i, valor) )
}
reduce <- function(i, xi) {
keyval(i, sum(xi))
}
calc <- mapreduce(input=M,
#output=output,
#input.format="text",
map=map,
reduce=reduce,
verbose = FALSE)
C = values( from.dfs( calc ) )
C
}
library(rhdfs)
#Lectura de datos.
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/a.csv")
#Modificamos el nombre de las columnas por comodidad.
colnames(df) <- c("x","y","class")
#Analisis exploratorio del dataset.
#Podemos observar que hay 3 columnas.
head(df)
#Observamos cuantos elementos hay de cada clase.
table(df$class)
#0    1    2
#1000  999 1000
plot(datos$X, datos$Y, col = datos$class,
xlab = "X", ylab = "Y",
main = "Clustering Rectangular")
plot(df$X, df$Y, col = df$class,
xlab = "X", ylab = "Y",
main = "Clustering Rectangular")
plot(df$X, df$Y, col = df$class,
xlim = c(min(datos$X-100), max(datos$X+100)),
ylim = c(min(datos$Y-100), max(datos$Y+100)),
xlab = "X", ylab = "Y",
main = "Clustering Rectangular")
plot(df$X, df$Y, col = df$class,
xlim = c(min(df$X-100), max(df$X+100)),
ylim = c(min(df$Y-100), max(df$Y+100)),
xlab = "X", ylab = "Y",
main = "Clustering Rectangular")
#Lectura de datos.
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/a.csv")
#Modificamos el nombre de las columnas por comodidad.
colnames(df) <- c("x","y","class")
#Analisis exploratorio del dataset.
#Podemos observar que hay 3 columnas.
head(df)
#Observamos cuantos elementos hay de cada clase.
table(df$class)
#0    1    2
#1000  999 1000
plot(df$X, df$Y, col = df$class,
xlim = c(min(df$X-50), max(df$X+50)),
ylim = c(min(df$Y-50), max(df$Y+50)),
xlab = "X", ylab = "Y",
main = "Clustering Rectangular")
#Lectura de datos.
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/a.csv")
#Modificamos el nombre de las columnas por comodidad.
colnames(df) <- c("x","y","class")
#Analisis exploratorio del dataset.
#Podemos observar que hay 3 columnas.
head(df)
#Observamos cuantos elementos hay de cada clase.
table(df$class)
#0    1    2
#1000  999 1000
plot(df$X, df$Y, col = df$class,
xlim = c(min(df$X-30), max(df$X+30)),
ylim = c(min(df$Y-30), max(df$Y+30)),
xlab = "X", ylab = "Y",
main = "Clustering Rectangular")
#Lectura de datos.
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/a.csv")
#Modificamos el nombre de las columnas por comodidad.
colnames(df) <- c("x","y","class")
#Analisis exploratorio del dataset.
#Podemos observar que hay 3 columnas.
head(df)
#Observamos cuantos elementos hay de cada clase.
table(df$class)
#0    1    2
#1000  999 1000
plot(df$X, df$Y, col = df$class,
xlim = c(min(df$X-20), max(df$X+20)),
ylim = c(min(df$Y-20), max(df$Y+20)),
xlab = "X", ylab = "Y",
main = "Clustering Rectangular")
plot(df$x, df$y, col = df$class)
plot(df$x, df$y)
modelo.k.medias = kmeans(x = df[, c("x", "y")], centers = 3)
plot(x = df$x, y = df$y, col = modelo.k.medias$cluster)
points(x = modelo.k.medias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
plot(df$x, df$y), col = df$class)
plot(df$x, df$y, col = df$class)
head(df)
plot(df$x, df$y, col = df$class,
xlim = c(min(df$x-20), max(df$x+20)),
ylim = c(min(df$y-0), max(df$y+20)),
xlab = "X", ylab = "Y",
main = "Clustering Rectangular")
plot(df$x, df$y)
table(modelo.k.medias$cluster, df$class)
modelo.k.medias$cluster
df$class
modelo.k.medias$cluster
modelo.k.medias
matrizconfusion <- table(df$class,modelo.k.medias$cluster,dnn=c("Valor Real", "Prediccion"))
matrizconfusion
matrizconfusion <- table(df$class,modelo.k.medias$cluster,dnn=c("Valor Real", "Cluster"))
matrizconfusion
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/a_big.csv")
View(df)
View(df)
colnames(df) <- c("x","y","class")
plot(df$x, df$y)
modelo.k.medias = kmeans(x = df[, c("x", "y")], centers = 3)
plot(x = df$x, y = df$y, col = modelo.k.medias$cluster)
points(x = modelo.k.medias$centers[, c("x", "y")], col = 1:4, pch = 19, cex = 3)
table(df$class)
matrizconfusion <- table(df$class,modelo.k.medias$cluster,dnn=c("Valor Real", "Cluster"))
matrizconfusion
df = read.csv(file = "C:/Users/Eric/Desktop/AprendizajeNoSupervisado/data/good_luck.csv")
colnames(df)[11] <- "class"
table(df$class)
plot(df)
plot(df)
modelo.k.medias = kmeans(x = df[, -c("class")], centers = 3)
head(df)
modelo.k.medias = kmeans(x = df[, c("X.0.262989", "X.0.868793", "X0.133290" ,
"X2.745286", "X.0.047937", "X1.357079", "X.0.499947",
"X.1.874985", "X.0.395397","X1.563203")], centers = 3)
table(modelo.k.medias$cluster, df$class)
modelo.k.medias = kmeans(x = df[, c("X.0.262989", "X.0.868793", "X0.133290" ,
"X2.745286", "X.0.047937", "X1.357079", "X.0.499947",
"X.1.874985", "X.0.395397","X1.563203")], centers = 2)
table(modelo.k.medias$cluster, df$class)
entrada.num = df
entrada.num$Class = NULL
entrada.num = as.matrix(entrada.num)
distancia = dist(entrada.num)
distancia
cluster = hclust(distancia, method = metodo)
metodo = "complete"
cluster = hclust(distancia, method = metodo)
plot(cluster)
nclases = 2
corte = cutree(cluster, k=nclases)
table(df$class, corte)
corte = cutree(cluster, h=15)
unique(corte)
corte = cutree(cluster, h=13)
unique(corte)
corte = cutree(cluster, h=5)
unique(corte)
corte = cutree(cluster, h=9)
unique(corte)
corte = cutree(cluster, h=11)
# Verificamos cuántos clúster tenemos
unique(corte)
corte = cutree(cluster, h=10)
unique(corte)
corte = cutree(cluster, h=9.5)
# Verificamos cuántos clúster tenemos
unique(corte)
corte = cutree(cluster, h=9.0)
# Verificamos cuántos clúster tenemos
unique(corte)
corte = cutree(cluster, h=9.2)
# Verificamos cuántos clúster tenemos
unique(corte)
corte = cutree(cluster, h=9.3)
# Verificamos cuántos clúster tenemos
unique(corte)
table(df$class, corte)
plot(df)
x <- c(2,6,67,85,7,9,4,21,78,45)
cle <- ifelse (x %% 2 == 0, 1, 2)
cle
keyval(cle,x)
x <- c(2,6,67,85,7,9,4,21,78,45)
cle <- ifelse (x %% 2 == 0, 1, 2)
keyval(cle,x)
library(rmr2)
ignore <- rmr.options(backend="local") # Opciones "local" o "hadoop"
?rpart
install.packages("rpart")
install.packages("rpart")
install.packages('rpart')
iris
kmeans(iris,k=2)
?kmeans
kmeans(iris,2)
newiris <- iris
newiris$Species <- NULL
kc <- kmeans(newiris, 3)
table(iris$Species, kc ,dnn = c("Valor","prediccion"))
newiris <- iris
newiris$Species <- NULL
kc <- kmeans(newiris, 3)
table(iris$Species, kc ,dnn = c("Valor","prediccion"))
table(iris$Species, kc)
table(iris$Species, kc)
table(iris$Species, kc$cluster ,dnn = c("Valor","prediccion"))
table(kc$cluster, iris$Species ,dnn = c("prediccion","Valor"))
x<-table(kc$cluster, iris$Species ,dnn = c("prediccion","Valor"))
x[1,]
sum(x[1,])
x<-table(kc$cluster, iris$Species ,dnn = c("prediccion","Valor"))
x
setwd("C:/Users/Eric/Desktop/recomendacion-modelos/")
ejemplo <- read.csv("ejemplo.csv")
View(ejemplo)
periodico <- read.csv("ejemplo.csv")
View(periodico)
View(periodico)
